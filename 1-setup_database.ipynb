{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies - only need to uncomment/run this once for each environment\n",
    "\n",
    "# %cd /notebooks/cerulean-notebook\n",
    "\n",
    "# Install required packages for python\n",
    "# %pip install -r requirements.txt\n",
    "\n",
    "# Install required command line tools\n",
    "# Run this line for apt-based systems (e.g. Debian, Ubuntu, Linux Mint)\n",
    "# !apt-get install -y wget\n",
    "\n",
    "# Run this line for MacOS (requires Homebrew from https://brew.sh/)\n",
    "# !brew install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set up Physionet credentials\n",
    "phys_pass = %env PHYSIONET_PASSWORD\n",
    "phys_user = %env PHYSIONET_USERNAME\n",
    "data_dir  = %env DATA_DIR\n",
    "\n",
    "\n",
    "# Create or load a persistent database with DuckDB\n",
    "# Load SQL extension\n",
    "%load_ext sql\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DuckDB (creates a new database if it doesn't exist)\n",
    "db_state = pd.DataFrame()\n",
    "%sql db_state << select table_schema, table_name from information_schema.tables\n",
    "display(db_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to parquet\n",
    "\n",
    "# DEBUG WITH ONE TABLE\n",
    "# db_state = %sql select table_schema, table_name from information_schema.tables LIMIT 1\n",
    "\n",
    "if db_state.shape[0] == 35:\n",
    "    for schema in db_state['table_schema'].unique():\n",
    "        # Create directory for schema\n",
    "        !mkdir -p $data_dir/parquet/$schema\n",
    "        # !mkdir -p parquet/$schema\n",
    "        for table in db_state[db_state['table_schema'] == schema]['table_name']:\n",
    "            print(\"Exporting \" + schema + \".\" + table + \" to parquet\")\n",
    "            %sql COPY {{schema}}.{{table}} TO '{{data_dir}}/parquet/{{schema}}/{{table}}.parquet' (FORMAT PARQUET);\n",
    "else:\n",
    "    print(\"Expected 35 tables, found \" + str(db_state.shape[0]) + \". Skipping export to parquet.\")\n",
    "    exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP!\n",
    "\n",
    "## If that ran successfully, you can skip the data import steps below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data into data/ folder \n",
    "source = {\n",
    "    'mimiciv': 'https://physionet.org/files/mimiciv/2.2/', \n",
    "    'mimiciv_note': 'https://physionet.org/files/mimic-iv-note/2.2/',\n",
    "    'phenotype_annotations': 'https://physionet.org/files/phenotype-annotations-mimic/1.20.03/'\n",
    "}\n",
    "\n",
    "# for url in source.values():\n",
    "#     !wget -r -N -c -np -P data/ --user \"$phys_user\" --password \"$phys_pass\" $url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract columns and data_types for each table (run on a previous manual data load)\n",
    "# %sql columns << SELECT table_schema, table_name, column_name, data_type FROM information_schema.columns;\n",
    "# columns.to_csv('data/physionet_schema.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the column data_types saved from manual load\n",
    "raw_col = pd.read_csv('data/physionet_schema.csv', delimiter='\\t')\n",
    "raw_col['param'] = '\\'' + raw_col['column'] + '\\': \\'' + raw_col['data_type']  + '\\''\n",
    "\n",
    "# Aggregate the column data_types for each schema.table\n",
    "df_col = raw_col.groupby(['schema', 'table'])['param'].aggregate(\", \".join).reset_index()\n",
    "df_col['param'] = 'columns={' + df_col['param'] + '}'\n",
    "\n",
    "# Pass into a dict, keys are (schema, table) tuples\n",
    "col = df_col.set_index(['schema', 'table']).to_dict()['param']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create a schema for each data source\n",
    "# and a table for each file (*.csv.gz) in its directory\n",
    "\n",
    "def create_schema_and_tables(schema, path):\n",
    "    files = listdir(path)\n",
    "    %sql CREATE SCHEMA IF NOT EXISTS {{schema}};\n",
    "    for file in files:\n",
    "        if file.endswith('.csv.gz'):\n",
    "            table = file.split('.')[0]\n",
    "            param = col.get((schema, table), 'AUTO_DETECT=TRUE')\n",
    "            %sql DROP TABLE IF EXISTS {{schema}}.{{table}};\n",
    "            %sql CREATE TABLE {{schema}}.{{table}} AS SELECT * FROM read_csv('{{path}}{{file}}', header=True, {{param}} );\n",
    "    %sql result << SELECT table_schema, table_name FROM information_schema.tables WHERE table_schema = '{{schema}}';\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MIMIC-IV Notes\n",
    "schema = 'mimiciv_note'\n",
    "path = 'data/physionet.org/files/mimic-iv-note/2.2/note/'\n",
    "\n",
    "# create_schema_and_tables(schema, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MIMIC-IV ICU\n",
    "schema = 'mimiciv_icu'\n",
    "path = 'data/physionet.org/files/mimiciv/2.2/icu/'\n",
    "\n",
    "# create_schema_and_tables(schema, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MIMIC-IV Hospital\n",
    "schema = 'mimiciv_hosp'\n",
    "path = 'data/physionet.org/files/mimiciv/2.2/hosp/'\n",
    "\n",
    "# create_schema_and_tables(schema, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    # 'mimiciv_hosp': 'data/physionet.org/files/mimiciv/2.2/hosp/',\n",
    "    # 'mimiciv_icu': 'data/physionet.org/files/mimiciv/2.2/icu/',\n",
    "    'mimiciv_note': 'data/physionet.org/files/mimic-iv-note/2.2/note/'\n",
    "}\n",
    "\n",
    "for schema, path in datasets.items():\n",
    "    create_schema_and_tables(schema, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
