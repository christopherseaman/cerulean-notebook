{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "data_get.sh: 5: wget: not found\n",
      "data_get.sh: 8: wget: not found\n",
      "data_get.sh: 11: wget: not found\n"
     ]
    }
   ],
   "source": [
    "# Install required packages and download data\n",
    "%pip install -q -r requirements.txt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "!sh data_get.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from os import listdir \n",
    "\n",
    "# Load SQL extension\n",
    "%load_ext sql\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "\n",
    "# Connect to DuckDB\n",
    "%sql duckdb:///cerulean.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the column names and data_types for each table from manual load (not shown)\n",
    "# %sql columns << SELECT table_schema, table_name, column_name, data_type FROM information_schema.columns;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the column data_types saved from manual load\n",
    "raw_col = pd.read_csv('column_schema.csv', delimiter='\\t')\n",
    "raw_col['param'] = '\\'' + raw_col['column'] + '\\': \\'' + raw_col['data_type']  + '\\''\n",
    "\n",
    "# Aggregate the column data_types for each schema.table\n",
    "df_col = raw_col.groupby(['schema', 'table'])['param'].aggregate(\", \".join).reset_index()\n",
    "df_col['param'] = 'columns={' + df_col['param'] + '}'\n",
    "\n",
    "# Pass into a dict, keys are (schema, table) tuples\n",
    "col = df_col.set_index(['schema', 'table']).to_dict()['param']\n",
    "\n",
    "# Set `columns={}` if known, otherwise use AUTO_DETECT\n",
    "# e.g.: col.get(('mimiciv_hosp', 'pharmacy'), 'AUTO_DETECT=TRUE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create a schema for each data source\n",
    "# and a table for each file (*.csv.gz) in its directory\n",
    "\n",
    "def create_schema_and_tables(schema, path):\n",
    "    files = listdir(path)\n",
    "    %sql CREATE SCHEMA IF NOT EXISTS {schema};\n",
    "    for file in files:\n",
    "        if file.endswith('.csv.gz'):\n",
    "            table = file.split('.')[0]\n",
    "            param = col.get((schema, table), 'AUTO_DETECT=TRUE')\n",
    "            %sql DROP TABLE IF EXISTS {schema}.{table};\n",
    "            %sql CREATE TABLE {schema}.{table} AS SELECT * FROM read_csv('{path}{file}', header=True, {param} );\n",
    "    %sql result << SELECT table_schema, table_name FROM information_schema.tables WHERE table_schema = '{schema}';\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MIMIC-IV Hospital\n",
    "schema = 'mimiciv_hosp'\n",
    "path = 'physionet.org/files/mimiciv/2.2/hosp/'\n",
    "\n",
    "create_schema_and_tables(schema, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MIMIC-IV ICU\n",
    "schema = 'mimiciv_icu'\n",
    "path = 'physionet.org/files/mimiciv/2.2/icu/'\n",
    "\n",
    "create_schema_and_tables(schema, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MIMIC-IV Notes\n",
    "schema = 'mimiciv_note'\n",
    "path = 'physionet.org/files/mimic-iv-note/2.2/note/'\n",
    "\n",
    "create_schema_and_tables(schema, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
